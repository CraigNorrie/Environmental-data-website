---
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
#Load the packages required for this 
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
library(htmltools)
select <- dplyr::select #This ensures that the select function is taken from dplyr and not another package
```

# Environmental data from aquaculture

Environmental data displayed in this repository has been collected at aquaculture locations throughout Puget sound as part of an ongoing project. Data displayed here has not been quality controlled. Suggestions for additions or alterations to this page please contact Craig Norrie - [cnorrie@uw.edu](cnorrie@uw.edu)

## Map of sites

Click each location on this map to find a list of the data that has been collected at each site and the organisation that has collected this data. 

```{r, echo = FALSE, results = "hide", include=FALSE}
###Create the map
#Read in site info
siteinfo <- read.csv(here("Site_info.csv"))
#Create the map - in the future set all of the variables in a csv to be read in 
aquaculturemap <- leaflet() %>% 
  addProviderTiles(providers$Esri.OceanBasemap) %>% 
  addMarkers(lng = siteinfo$Long, lat = siteinfo$Lat,
             popup = lapply(seq(nrow(siteinfo)), function(i) {
               HTML(paste0("<strong>", siteinfo$Site_name[i], "</strong><br>",
                           "Availble data: ", siteinfo$Data[i], "<br>",
                           "Organisation: ", siteinfo$Organisation[i], "<br>",
                           "Contact: ", siteinfo$Contact[i]))
             }))

```

```{r, echo = FALSE}
aquaculturemap
```

## Comparison of data across sites

The following figures allow the comparison of data across all sites over the duration that the data was collected. 

### Disolved oxygen

At intertidal sites, these daily averages include time that the sensors were not in the water. 

```{r, include=FALSE}
#Create averages
##read in the data 
allthorndat <- read.csv(here("Data/Thorndyke","UW_THORNDYKE_DO_TEMP_WATERLEVEL_2023_2024.csv"))
allcheldat <- read.csv(here("Data/Eld","UW_ELD_DO_TEMP_WATERLEVEL_2023_2024.csv"))
allhooddat <- read.csv(here("Data/Hood Head","UW_HOODHEAD_DO_TEMP_2023_2024.csv"))
allmandat <- read.csv(here("Data/Clam Bay","UW_CLAMBAY_DO_TEMP_2023_2024.csv"))
#Totten inlet data is in a slightly different format to the other UW data
alltotdat <- read.csv(here("Data/Totten","PSI_TOTTENINLET_DO_WATERLEVEL_lowerbags_2023_2024.csv"))%>% 
  select(Date.Time..GMT.07.00, Temp_C, Dissolved_Oxygen_mg_l, Site, Tide..ft.) %>% 
  mutate(DO_mgL = Dissolved_Oxygen_mg_l,
         water_level = Tide..ft. )
#Set the first column as date
allthorndat$datetime <- mdy_hm(allthorndat$Date.Time..GMT.07.00)
allcheldat$datetime  <- mdy_hm(allcheldat$Date.Time..GMT.07.00)
allhooddat$datetime  <- mdy_hm(allhooddat$Date.Time..GMT.07.00)
allmandat$datetime  <- mdy_hm(allmandat$Date.Time..GMT.07.00)
alltotdat <- alltotdat %>% 
  mutate(datetime = parse_date_time(Date.Time..GMT.07.00, orders = c("mdy_HM", "ymd_HM")))#Checks both date formats
#add a site column to each of the DFs
allcheldat <- allcheldat %>% mutate(Site = "Eld Inlet")
allthorndat <- allthorndat %>% mutate(Site = "Thorndyke Bay")
allhooddat <- allhooddat %>% mutate(Site = "Hood Head")
allmandat <- allmandat %>% mutate(Site = "Clam Bay")
alltotdat <- alltotdat %>% mutate(Site = "Totten Inlet")
#add a date column to the two dfs
allcheldat$date <- as.Date(allcheldat$datetime)
allthorndat$date <- as.Date(allthorndat$datetime)
allhooddat$date <- as.Date(allhooddat$datetime)
allmandat$date <- as.Date(allmandat$datetime)
alltotdat$date <- as.Date(alltotdat$datetime)
#calculate averages
#Need to do Chelsea and totten Do seperatley becaue the times when the sensors were exposed need to be removed
chelav <- allcheldat %>% group_by(date) %>% summarise(
    meantemp = mean(Temp_C, na.rm = TRUE),
    meanDO = mean(DO_mgL[water_level > -0.5], na.rm = TRUE)#Filtered to only obtain data when the sensor was wet
  )
totav <- alltotdat %>% group_by(date) %>% summarise(
    meantemp = mean(Temp_C, na.rm = TRUE),
    meanDO = mean(DO_mgL[water_level > -2], na.rm = TRUE)
  )
thornav <- allthorndat %>% group_by(date) %>% summarise(
    meantemp = mean(Temp_C, na.rm = TRUE),
    meanDO = mean(DO_mgL[water_level > -2], na.rm = TRUE)
  )
manav <- allmandat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
hoodav <- allhooddat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))




#Only caclulate the days I want
chelav <- chelav %>% filter(date > "2023-06-05")
thornav <- thornav %>% filter(date > "2023-06-05")
hoodav <- hoodav %>% filter(date > "2023-06-05")
manav <- manav %>% filter(date > "2023-06-05")
totav <- totav %>%  filter(date > "2023-06-05")
#Add site to the average dfs
chelav <- chelav %>% mutate(Site = "Eld_Inlet, Chelsea")
thornav <- thornav %>% mutate(Site = "Thorndyke")
manlav <- manav %>% mutate(Site = "Manchester")
hoodav <- hoodav %>% mutate(Site = "Hood_Head")
totav <- totav %>% mutate(Site = "Totten_Inlet")
#merge the two sites temperature data to plot
alldat <- bind_rows(allcheldat, allthorndat, allmandat, allhooddat, alltotdat)
allavdat <- bind_rows(chelav, thornav, hoodav, manav, totav)
dailyaverages <- alldat
alldat$date <- as.Date(alldat$datetime) 
averagetemps <- alldat %>% group_by(date, Site) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE))
averageDO <- alldat %>% group_by(date, Site) %>% summarise(meanDO=mean(DO_mgL, na.rm = TRUE))

#Plot DO
avergage_DO_plot <- averageDO %>% 
  filter(date > "2023-06-08") %>% #filter(date < "2023-10-17") %>% 
  ggplot(aes(x= date , y = meanDO, colour = Site)) + geom_line()+
  theme_bw()+ylab("Daily Mean Dissolved Oxygen (mg / L)")+xlab("Date")+
  scale_color_manual(values=c("#B3C863","#756A8C","#037D64","#CEB08E","Red"))+
  theme(axis.title.y=element_text())+
  theme(
    text = element_text(size = 14))

```

```{r, echo=FALSE}
ggplotly(avergage_DO_plot)
```

### Temperature
Note that these daily averages include time that individuals were out of the water at low tide sites.

```{r, include = FALSE}
average_temp_plot <- averagetemps %>% 
  filter(date > "2023-06-08") %>% #filter(date < "2023-10-17") %>% 
           ggplot(aes(x= date , y = meantemp, colour = Site)) + geom_line()+
  theme_bw()+ylab("Daily Mean Temperature (Â°C)")+xlab("Date")+
  scale_color_manual(values=c("#B3C863","#756A8C","#037D64","#CEB08E", "red"))+
  theme(text=element_text(),
        axis.title.y=element_text())
```

```{r, echo=FALSE}
ggplotly(average_temp_plot)
```

```{r, echo=FALSE, include=FALSE}
#carbchem <- read.csv(here("Data","carbchem.csv"))
```

