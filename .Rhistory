##read in the data
allthorndat <- read.csv(here("Data","thorn_Do_Temp.csv"))
allcheldat <- read.csv(here("Data","chelsea_Do_Temp.csv"))
allhooddat <- read.csv(here("Data","hood_Do_Temp.csv"))
allmandat <- read.csv(here("Data","man_Do_Temp.csv"))
#Set the first column as date
allthorndat$datetime <- mdy_hm(allthorndat$Date.Time..GMT.07.00)
allcheldat$datetime  <- mdy_hm(allcheldat$Date.Time..GMT.07.00)
allhooddat$datetime  <- mdy_hm(allhooddat$Date.Time..GMT.07.00)
allmandat$datetime  <- mdy_hm(allmandat$Date.Time..GMT.07.00)
#add a site columin to each of the DFs
allcheldat <- allcheldat %>% mutate(Site = "Chelsea")
allthorndat <- allthorndat %>% mutate(Site = "Thorndyke")
allhooddat <- allhooddat %>% mutate(Site = "Hood_Head")
allmandat <- allmandat %>% mutate(Site = "Manchester")
#add a date column to the two dfs
allcheldat$date <- as.Date(allcheldat$datetime)
allthorndat$date <- as.Date(allthorndat$datetime)
allhooddat$date <- as.Date(allhooddat$datetime)
allmandat$date <- as.Date(allmandat$datetime)
#calculate averages
chelav <- allcheldat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
thornav <- allthorndat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
manav <- allmandat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
hoodav <- allhooddat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
#Only caclulate the days I want
chelav <- chelav %>% filter(date > "2023-06-05")
thornav <- thornav %>% filter(date > "2023-06-05")
hoodav <- hoodav %>% filter(date > "2023-06-05")
manav <- manav %>% filter(date > "2023-06-05")
#calculate cumulative degree days
chelav$degdays <- cumsum(chelav$meantemp)
thornav$degdays <- cumsum(thornav$meantemp)
#Add site to the average dfs
chelav <- chelav %>% mutate(Site = "Chelsea")
thornav <- thornav %>% mutate(Site = "Thorndyke")
manlav <- manav %>% mutate(Site = "Manchester")
hoodav <- hoodav %>% mutate(Site = "Hood_Head")
#merge the two sites temperature data to plot
alldat <- bind_rows(allcheldat, allthorndat, allmandat, allhooddat)
allavdat <- bind_rows(chelav, thornav, hoodav, manav)
dailyaverages <- alldat
alldat$date <- as.Date(alldat$datetime)
averagetemps <- alldat %>% group_by(date, Site) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE))
averageDO <- alldat %>% group_by(date, Site) %>% summarise(meanDO=mean(DO_mgL, na.rm = TRUE))
#Plot DO
avergage_DO_plot <- averageDO %>%
filter(date > "2023-06-05") %>% #filter(date < "2023-10-17") %>%
ggplot(aes(x= date , y = meanDO, colour = Site)) + geom_line()+
theme_bw()+ylab("Daily Mean Dissolved Oxygen (mg / L)")+xlab("Date")+
scale_color_manual(values=c("#B3C863","#756A8C","#037D64","#CEB08E"))+
theme(axis.title.y=element_text())+
theme(
text = element_text(size = 14))
# Chunk 5
ggplotly(avergage_DO_plot)
# Chunk 6
averagetemps <- averagetemps %>%
filter(date > "2023-06-05") %>% #filter(date < "2023-10-17") %>%
ggplot(aes(x= date , y = meantemp, colour = Site)) + geom_line()+
theme_bw()+ylab("Daily Mean Temperature (°C)")+xlab("Date")+
scale_color_manual(values=c("#B3C863","#756A8C","#037D64","#CEB08E"))+
theme(text=element_text(),
axis.title.y=element_text())
# Chunk 7
ggplotly(averagetemps)
# Chunk 8
carbchem <- read.csv(here("Data","carbchem.csv"))
carbchem %>% filter(Site == "Chelsea") %>% select(-c(1)) %>%
```
carbchem %>% filter(Site == "Chelsea") %>% select(-c(1))
carbchem %>% filter(Site == "Chelsea") %>% select(-c(1,2))
carbchem %>% filter(Site == "Chelsea") %>% select(-c(1,2)) %>%  arrange(Year, Month)
carbchem %>% filter(Site == "Hood Head") %>% select(-c(1,2)) %>%  arrange(Year, Month)
carbchem <- read.csv(here("Data","carbchem.csv"))
carbchem %>% filter(Site == "Hood Head") %>% select(-c(1,2)) %>%  arrange(Year, Month)
carbchem %>% filter(Site == "Manchester") %>% select(-c(1,2)) %>%  arrange(Year, Month)
carbchem %>% filter(Site == "Thorndyke") %>% select(-c(1,2)) %>%  arrange(Year, Month)
---
title: "Thorndyke Bay environmental data"
# Chunk 1
#Load the packages required to make a local scale map
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
library(lubridate)
# Chunk 2
###Create the map
#Set the content for each point on the map
content_thorndyke_UW <- paste("<b>Thorndyke Bay, Baywater Shellfish - UW</b><br/>
Data: Disolved oxygen, temperature, salinity<br/>
Contact: Craig Norrie")
content_thorndyke_PSI <- paste("<b>Thorndyke Bay, Baywater Shellfish - UW</b><br/>
Data: data link<br/>
Contact: PSI")
content_thorndyke_other <- paste("<b>Thorndyke Bay, Baywater Shellfish - UW</b><br/>
Data: Seaweed<br/>
Contact: Seaweed")
#Create the map - in the future set all of the variables in a csv to be read in
aquaculturemap_thorn <- leaflet() %>%
addProviderTiles(providers$Esri.OceanBasemap) %>%
addMarkers(lng = -122.738067,lat = 47.808739, popup = content_thorndyke_UW) %>% #UW
addMarkers(lng = -122.735507,lat = 47.809411, popup = content_thorndyke_PSI) %>% #PSI
addMarkers(lng = -122.734758,lat = 47.809131, popup = content_thorndyke_other) #Other
# Chunk 3
aquaculturemap_thorn
# Chunk 4
#Sumarise the data
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
thornav <- thorndat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
# Chunk 5
Thorn_temp_plot <- thornav %>%
ggplot(aes(x = date, y = meantemp))+geom_line()+xlab("Date")+ylab("Temperature (°C)")+theme_bw()
# Chunk 6
ggplotly(Thorn_temp_plot)
# Chunk 7
Thorn_do_plot <- thornav %>%
ggplot(aes(x = date, y = meanDO))+geom_line()+xlab("Date")+ylab("Disolved oxygen (mg/L)")+theme_bw()
ggplotly(Thorn_do_plot)
# Chunk 8
ggplotly(Thorn_do_plot)
# Chunk 9
carbchem %>% filter(Site == "Thorndyke") %>% select(-c(1,2)) %>%  arrange(Year, Month)
# Chunk 1
#Load the packages required for this
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
library(htmltools)
# Chunk 2
###Create the map
#Read in site info
siteinfo <- read.csv(here("Site_info.csv"))
#Create the map - in the future set all of the variables in a csv to be read in
aquaculturemap <- leaflet() %>%
addProviderTiles(providers$Esri.OceanBasemap) %>%
addMarkers(lng = siteinfo$Long, lat = siteinfo$Lat,
popup = lapply(seq(nrow(siteinfo)), function(i) {
HTML(paste0("<strong>", siteinfo$Site_name[i], "</strong><br>",
"Availble data: ", siteinfo$Data[i], "<br>",
"Organisation: ", siteinfo$Organisation[i], "<br>",
"Contact: ", siteinfo$Contact[i]))
}))
# Chunk 3
aquaculturemap
# Chunk 4
#Create averages
##read in the data
allthorndat <- read.csv(here("Data","thorn_Do_Temp.csv"))
allcheldat <- read.csv(here("Data","chelsea_Do_Temp.csv"))
allhooddat <- read.csv(here("Data","hood_Do_Temp.csv"))
allmandat <- read.csv(here("Data","man_Do_Temp.csv"))
#Set the first column as date
allthorndat$datetime <- mdy_hm(allthorndat$Date.Time..GMT.07.00)
allcheldat$datetime  <- mdy_hm(allcheldat$Date.Time..GMT.07.00)
allhooddat$datetime  <- mdy_hm(allhooddat$Date.Time..GMT.07.00)
allmandat$datetime  <- mdy_hm(allmandat$Date.Time..GMT.07.00)
#add a site columin to each of the DFs
allcheldat <- allcheldat %>% mutate(Site = "Chelsea")
allthorndat <- allthorndat %>% mutate(Site = "Thorndyke")
allhooddat <- allhooddat %>% mutate(Site = "Hood_Head")
allmandat <- allmandat %>% mutate(Site = "Manchester")
#add a date column to the two dfs
allcheldat$date <- as.Date(allcheldat$datetime)
allthorndat$date <- as.Date(allthorndat$datetime)
allhooddat$date <- as.Date(allhooddat$datetime)
allmandat$date <- as.Date(allmandat$datetime)
#calculate averages
chelav <- allcheldat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
thornav <- allthorndat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
manav <- allmandat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
hoodav <- allhooddat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
#Only caclulate the days I want
chelav <- chelav %>% filter(date > "2023-06-05")
thornav <- thornav %>% filter(date > "2023-06-05")
hoodav <- hoodav %>% filter(date > "2023-06-05")
manav <- manav %>% filter(date > "2023-06-05")
#calculate cumulative degree days
chelav$degdays <- cumsum(chelav$meantemp)
thornav$degdays <- cumsum(thornav$meantemp)
#Add site to the average dfs
chelav <- chelav %>% mutate(Site = "Chelsea")
thornav <- thornav %>% mutate(Site = "Thorndyke")
manlav <- manav %>% mutate(Site = "Manchester")
hoodav <- hoodav %>% mutate(Site = "Hood_Head")
#merge the two sites temperature data to plot
alldat <- bind_rows(allcheldat, allthorndat, allmandat, allhooddat)
allavdat <- bind_rows(chelav, thornav, hoodav, manav)
dailyaverages <- alldat
alldat$date <- as.Date(alldat$datetime)
averagetemps <- alldat %>% group_by(date, Site) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE))
averageDO <- alldat %>% group_by(date, Site) %>% summarise(meanDO=mean(DO_mgL, na.rm = TRUE))
#Plot DO
avergage_DO_plot <- averageDO %>%
filter(date > "2023-06-05") %>% #filter(date < "2023-10-17") %>%
ggplot(aes(x= date , y = meanDO, colour = Site)) + geom_line()+
theme_bw()+ylab("Daily Mean Dissolved Oxygen (mg / L)")+xlab("Date")+
scale_color_manual(values=c("#B3C863","#756A8C","#037D64","#CEB08E"))+
theme(axis.title.y=element_text())+
theme(
text = element_text(size = 14))
# Chunk 5
ggplotly(avergage_DO_plot)
# Chunk 6
averagetemps <- averagetemps %>%
filter(date > "2023-06-05") %>% #filter(date < "2023-10-17") %>%
ggplot(aes(x= date , y = meantemp, colour = Site)) + geom_line()+
theme_bw()+ylab("Daily Mean Temperature (°C)")+xlab("Date")+
scale_color_manual(values=c("#B3C863","#756A8C","#037D64","#CEB08E"))+
theme(text=element_text(),
axis.title.y=element_text())
# Chunk 7
ggplotly(averagetemps)
# Chunk 8
carbchem <- read.csv(here("Data","carbchem.csv"))
# Chunk 1
#Load the packages required to make a local scale map
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
library(lubridate)
# Chunk 2
aquaculturemap_chel <- leaflet() %>%
addProviderTiles(providers$Esri.OceanBasemap) %>%
addMarkers(lng = -122.960441,lat = 47.127609, popup = "South Sound - Chelsea Farms")
# Chunk 3
aquaculturemap_chel
# Chunk 4
#Sumarise the data
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
cheldat <- read.csv(here("Data", "chelsea_Do_Temp.csv"))#Read in the data
cheldat$datetime <- mdy_hm(cheldat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a separate script and this should be saved for the website only
chelav <- cheldat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
# Chunk 5
chel_temp_plot <- chelav %>%
ggplot(aes(x = date, y = meantemp))+geom_line()+xlab("Date")+ylab("Temperature (°C)")+theme_bw()
# Chunk 6
ggplotly(chel_temp_plot)
# Chunk 7
chel_do_plot <- chelav %>%
ggplot(aes(x = date, y = meanDO))+geom_line()+xlab("Date")+ylab("Disolved oxygen (mg/L)")+theme_bw()
ggplotly(chel_do_plot)
# Chunk 8
ggplotly(chel_do_plot)
# Chunk 9
carbchem %>% filter(Site == "Chelsea") %>% select(-c(1,2)) %>%  arrange(Year, Month)
# Chunk 1
#Load the packages required to make a local scale map
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
library(lubridate)
# Chunk 2
aquaculturemap_hood <- leaflet() %>%
addProviderTiles(providers$Esri.OceanBasemap) %>%
addMarkers(lng = -122.612914,lat = 47.884253, popup = "Hood Head - Blue Dot Sea Farm") #Hood Head
# Chunk 3
aquaculturemap_hood
# Chunk 4
#Sumarise the data
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
hooddat <- read.csv(here("Data", "hood_Do_Temp.csv"))#Read in the data
hooddat$datetime <- mdy_hm(hooddat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
hoodav <- hooddat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
# Chunk 5
hood_temp_plot <- hoodav %>%
ggplot(aes(x = date, y = meantemp))+geom_line()+xlab("Date")+ylab("Temperature (°C)")+theme_bw()
# Chunk 6
ggplotly(hood_temp_plot)
# Chunk 7
hood_do_plot <- hoodav %>%
ggplot(aes(x = date, y = meanDO))+geom_line()+xlab("Date")+ylab("Disolved oxygen (mg/L)")+theme_bw()#+geom_blank()
ggplotly(hood_do_plot)
# Chunk 8
ggplotly(hood_do_plot)
# Chunk 9
carbchem %>% filter(Site == "Hood Head") %>% select(-c(1,2)) %>%  arrange(Year, Month)
# Chunk 1
#Load the packages required to make a local scale map
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
library(lubridate)
# Chunk 2
aquaculturemap_man <- leaflet() %>%
addProviderTiles(providers$Esri.OceanBasemap) %>%
addMarkers(lng = -122.545044,lat = 47.573528, popup = "Clam Bay - NOAA Manchester")
# Chunk 3
aquaculturemap_man
# Chunk 4
#Sumarise the data
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
mandat <- read.csv(here("Data", "man_Do_Temp.csv"))#Read in the data
mandat$datetime <- mdy_hm(mandat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
manav <- mandat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
# Chunk 5
man_temp_plot <- manav %>%
ggplot(aes(x = date, y = meantemp))+geom_line()+xlab("Date")+ylab("Temperature (°C)")+theme_bw()
# Chunk 6
ggplotly(man_temp_plot)
# Chunk 7
man_do_plot <- manav %>%
ggplot(aes(x = date, y = meanDO))+geom_line()+xlab("Date")+ylab("Disolved oxygen (mg/L)")+theme_bw()
ggplotly(man_do_plot)
# Chunk 8
ggplotly(man_do_plot)
# Chunk 9
carbchem %>% filter(Site == "Manchester") %>% select(-c(1,2)) %>%  arrange(Year, Month)
# Chunk 1
#Load the packages required to make a local scale map
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
library(lubridate)
# Chunk 2
###Create the map
#Set the content for each point on the map
content_thorndyke_UW <- paste("<b>Thorndyke Bay, Baywater Shellfish - UW</b><br/>
Data: Disolved oxygen, temperature, salinity<br/>
Contact: Craig Norrie")
content_thorndyke_PSI <- paste("<b>Thorndyke Bay, Baywater Shellfish - UW</b><br/>
Data: data link<br/>
Contact: PSI")
content_thorndyke_other <- paste("<b>Thorndyke Bay, Baywater Shellfish - UW</b><br/>
Data: Seaweed<br/>
Contact: Seaweed")
#Create the map - in the future set all of the variables in a csv to be read in
aquaculturemap_thorn <- leaflet() %>%
addProviderTiles(providers$Esri.OceanBasemap) %>%
addMarkers(lng = -122.738067,lat = 47.808739, popup = content_thorndyke_UW) %>% #UW
addMarkers(lng = -122.735507,lat = 47.809411, popup = content_thorndyke_PSI) %>% #PSI
addMarkers(lng = -122.734758,lat = 47.809131, popup = content_thorndyke_other) #Other
# Chunk 3
aquaculturemap_thorn
# Chunk 4
#Sumarise the data
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
thornav <- thorndat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
# Chunk 5
Thorn_temp_plot <- thornav %>%
ggplot(aes(x = date, y = meantemp))+geom_line()+xlab("Date")+ylab("Temperature (°C)")+theme_bw()
# Chunk 6
ggplotly(Thorn_temp_plot)
# Chunk 7
Thorn_do_plot <- thornav %>%
ggplot(aes(x = date, y = meanDO))+geom_line()+xlab("Date")+ylab("Disolved oxygen (mg/L)")+theme_bw()
ggplotly(Thorn_do_plot)
# Chunk 8
ggplotly(Thorn_do_plot)
# Chunk 9
carbchem %>% filter(Site == "Thorndyke") %>% select(-c(1,2)) %>%  arrange(Year, Month)
---
output: html_document
# Chunk 1
#Load the packages required for this
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
library(htmltools)
# Chunk 2
###Create the map
#Read in site info
siteinfo <- read.csv(here("Site_info.csv"))
#Create the map - in the future set all of the variables in a csv to be read in
aquaculturemap <- leaflet() %>%
addProviderTiles(providers$Esri.OceanBasemap) %>%
addMarkers(lng = siteinfo$Long, lat = siteinfo$Lat,
popup = lapply(seq(nrow(siteinfo)), function(i) {
HTML(paste0("<strong>", siteinfo$Site_name[i], "</strong><br>",
"Availble data: ", siteinfo$Data[i], "<br>",
"Organisation: ", siteinfo$Organisation[i], "<br>",
"Contact: ", siteinfo$Contact[i]))
}))
# Chunk 3
aquaculturemap
# Chunk 4
#Create averages
##read in the data
allthorndat <- read.csv(here("Data","thorn_Do_Temp.csv"))
allcheldat <- read.csv(here("Data","chelsea_Do_Temp.csv"))
allhooddat <- read.csv(here("Data","hood_Do_Temp.csv"))
allmandat <- read.csv(here("Data","man_Do_Temp.csv"))
#Set the first column as date
allthorndat$datetime <- mdy_hm(allthorndat$Date.Time..GMT.07.00)
allcheldat$datetime  <- mdy_hm(allcheldat$Date.Time..GMT.07.00)
allhooddat$datetime  <- mdy_hm(allhooddat$Date.Time..GMT.07.00)
allmandat$datetime  <- mdy_hm(allmandat$Date.Time..GMT.07.00)
#add a site columin to each of the DFs
allcheldat <- allcheldat %>% mutate(Site = "Chelsea")
allthorndat <- allthorndat %>% mutate(Site = "Thorndyke")
allhooddat <- allhooddat %>% mutate(Site = "Hood_Head")
allmandat <- allmandat %>% mutate(Site = "Manchester")
#add a date column to the two dfs
allcheldat$date <- as.Date(allcheldat$datetime)
allthorndat$date <- as.Date(allthorndat$datetime)
allhooddat$date <- as.Date(allhooddat$datetime)
allmandat$date <- as.Date(allmandat$datetime)
#calculate averages
chelav <- allcheldat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
thornav <- allthorndat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
manav <- allmandat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
hoodav <- allhooddat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
#Only caclulate the days I want
chelav <- chelav %>% filter(date > "2023-06-05")
thornav <- thornav %>% filter(date > "2023-06-05")
hoodav <- hoodav %>% filter(date > "2023-06-05")
manav <- manav %>% filter(date > "2023-06-05")
#calculate cumulative degree days
chelav$degdays <- cumsum(chelav$meantemp)
thornav$degdays <- cumsum(thornav$meantemp)
#Add site to the average dfs
chelav <- chelav %>% mutate(Site = "Chelsea")
thornav <- thornav %>% mutate(Site = "Thorndyke")
manlav <- manav %>% mutate(Site = "Manchester")
hoodav <- hoodav %>% mutate(Site = "Hood_Head")
#merge the two sites temperature data to plot
alldat <- bind_rows(allcheldat, allthorndat, allmandat, allhooddat)
allavdat <- bind_rows(chelav, thornav, hoodav, manav)
dailyaverages <- alldat
alldat$date <- as.Date(alldat$datetime)
averagetemps <- alldat %>% group_by(date, Site) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE))
averageDO <- alldat %>% group_by(date, Site) %>% summarise(meanDO=mean(DO_mgL, na.rm = TRUE))
#Plot DO
avergage_DO_plot <- averageDO %>%
filter(date > "2023-06-05") %>% #filter(date < "2023-10-17") %>%
ggplot(aes(x= date , y = meanDO, colour = Site)) + geom_line()+
theme_bw()+ylab("Daily Mean Dissolved Oxygen (mg / L)")+xlab("Date")+
scale_color_manual(values=c("#B3C863","#756A8C","#037D64","#CEB08E"))+
theme(axis.title.y=element_text())+
theme(
text = element_text(size = 14))
# Chunk 5
ggplotly(avergage_DO_plot)
# Chunk 6
averagetemps <- averagetemps %>%
filter(date > "2023-06-05") %>% #filter(date < "2023-10-17") %>%
ggplot(aes(x= date , y = meantemp, colour = Site)) + geom_line()+
theme_bw()+ylab("Daily Mean Temperature (°C)")+xlab("Date")+
scale_color_manual(values=c("#B3C863","#756A8C","#037D64","#CEB08E"))+
theme(text=element_text(),
axis.title.y=element_text())
# Chunk 7
ggplotly(averagetemps)
# Chunk 8
carbchem <- read.csv(here("Data","carbchem.csv"))
#Sumarise the data
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
mandat <- read.csv(here("Data", "man_Do_Temp.csv"))#Read in the data
mandat$datetime <- mdy_hm(mandat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
manav <- mandat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
man_temp_plot <- manav %>%
ggplot(aes(x = date, y = meantemp))+geom_line()+xlab("Date")+ylab("Temperature (°C)")+theme_bw()
man_temp_plot
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
manav <- mandat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
man_temp_plot <- manav %>%
ggplot(aes(x = date, y = meantemp))+geom_line()+xlab("Date")+ylab("Temperature (°C)")+theme_bw()
man_temp_plot
View(manav)
View(mandat)
