quarto render
# Locations within thorndyke bay for sensors
```{r, echo = FALSE, results = "hide"}
#Load the packages required to make a local scale map
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
###Create the map
#Set the content for each point on the map
content_thorndyke_UW <- paste("<b>Thorndyke Bay, Baywater Shellfish - UW</b><br/>
Data: Disolved oxygen, temperature, salinity<br/>
Contact: Craig Norrie")
content_thorndyke_PSI <- paste("<b>Thorndyke Bay, Baywater Shellfish - UW</b><br/>
Data: data link<br/>
Contact: PSI")
content_thorndyke_Seaweed <- paste("<b>Thorndyke Bay, Baywater Shellfish - UW</b><br/>
Data: Seaweed<br/>
Contact: Seaweed")
#Create the map - in the future set all of the variables in a csv to be read in
aquaculturemap_thorn <- leaflet() %>%
addProviderTiles(providers$Esri.OceanBasemap) %>%
addMarkers(lng = -122.738067,lat = 47.808739, popup = content_thorndyke_UW) %>% #UW
addMarkers(lng = -122.735507,lat = 47.809411, popup = content_thorndyke_PSI) %>% #PSI
addMarkers(lng = -122.734758,lat = 47.809131, popup = content_thorndyke_Seaweed) #Seaweed
aquaculturemap_thorn
here()
library()here
library(here)
here()
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
View(thorndat)
Thorn_do_plot <- thorndat %>%
ggplot(aes(x = Date.Time..GMT.07.00, y = DO_mgL)+geom_line())
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
Thorn_do_plot <- thorndat %>%
ggplot(aes(x = Date.Time..GMT.07.00, y = DO_mgL)+geom_line())
str(thorndat)
thorndat <- as.Date(thorndat$Date.Time..GMT.07.00)
thorndat <- as.Date(thorndat$Date.Time..GMT.07.00)
thorndat$Date.Time..GMT.07.00 <- as.Date(thorndat$Date.Time..GMT.07.00)
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(allthorndat$Date.Time..GMT.07.00)
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
Thorn_do_plot <- thorndat %>%
ggplot(aes(x = Date.Time..GMT.07.00, y = DO_mgL)+geom_line())
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
Thorn_do_plot <- thorndat %>%
ggplot(aes(x = datetime, y = DO_mgL)+geom_line())
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
Thorn_do_plot <- thorndat %>%
ggplot(aes(x = datetime, y = DO_mgL))+geom_line()
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
Thorn_do_plot <- thorndat %>%
ggplot(aes(x = datetime, y = DO_mgL))+geom_line()
Thorn_do_plot
View(thorndat)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
thornav <- thorndat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
thornav <- thorndat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
Thorn_do_plot <- thornav %>%
ggplot(aes(x = date, y = DO_mgL))+geom_line()
Thorn_do_plot
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
thornav <- thorndat %>% group_by(date) %>% summarise(meanDO=mean(DO_mgL, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
Thorn_do_plot <- thornav %>%
ggplot(aes(x = date, y = meanDO))+geom_line()
View(thornav)
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
thornav <- thorndat %>% group_by(date) %>% summarise(meantemp=mean(Temp_C, na.rm = TRUE), meanDO=mean(DO_mgL, na.rm = TRUE))
Thorn_do_plot <- thornav %>%
ggplot(aes(x = date, y = meanDO))+geom_line()
Thorn_do_plot
View(thornav)
str(thornav)
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
thornav <- thorndat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
Thorn_do_plot <- thornav %>%
ggplot(aes(x = date, y = meanDO))+geom_line()
Thorn_do_plot
install.packages("plotly")
install.packages("Rtools")
library(sourcetools)
library(Rtools)
install.packages("Rtools")
version()
R.version
R.version
R.version
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
#Load the packages required to make a local scale map
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
install.packages("plotly")
install.packages(c("tidyverse", "leaflet", "here", "plotly", "leaflet.providers"))
library(tidyverse)
install.packages("tidyverse")
#Load the packages required to make a local scale map
library(tidyverse)
#Load the packages required for this
library(tidyverse)
install.packages("tidyverse")
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
#Load the packages required for this
library(tidyverse)
install.packages("tidyverse")
#Load the packages required for this
library(tidyverse)
install.packages("tidyverse")
install.packages("Rtools")
install.packages("tidyverse")
#Load the packages required to make a local scale map
library(tidyverse)
#Load the packages required to make a local scale map
library(tidyverse)
install.packages("tidyverse")
#Load the packages required to make a local scale map
library(tidyverse)
install.packages("gtable")
#Load the packages required to make a local scale map
library(tidyverse)
install.packages("munsell")
#Load the packages required to make a local scale map
library(tidyverse)
install.packages("utf8")
#Load the packages required to make a local scale map
library(tidyverse)
install.packages("tzdb")
#Load the packages required to make a local scale map
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
ggplotly(Thorn_do_plot)
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
thorndat <- read.csv(here("Data", "thorn_Do_Temp.csv"))#Read in the data
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
thornav <- thorndat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
thornav <- thorndat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
install.packages("lubridate")
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
mdy_hm
??mdy_hm
library(lubridate)
thorndat$datetime <- mdy_hm(thorndat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
thornav <- thorndat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
Thorn_do_plot <- thornav %>%
ggplot(aes(x = date, y = meanDO))+geom_line()+xlab("Date")+ylab("Disolved oxygen (mg/L)")
Thorn_do_plot
ggplotly(Thorn_do_plot)
ggplotly(Thorn_temp_plot)
#Load the packages required to make a local scale map
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
library(lubridate)
library(tidyverse)
library(leaflet)#package to make interactive web
library(leaflet.providers)#allows you to add third party basemaps
library(here)
library(plotly)
library(lubridate)
#Sumarise the data
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
cheldat <- read.csv(here("Data", "chel_Do_Temp.csv"))#Read in the data
#Sumarise the data
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
cheldat <- read.csv(here("Data", "chelsea_Do_Temp.csv"))#Read in the data
cheldat$datetime <- mdy_hm(cheldat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
chelav <- cheldat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
#Sumarise the data
#turn this into a loop that will do this for each of the cvs files that I have in the data folder
cheldat <- read.csv(here("Data", "chelsea_Do_Temp.csv"))#Read in the data
cheldat$datetime <- mdy_hm(cheldat$Date.Time..GMT.07.00)
#Obtain daily mean data - this should probably be done in a seperate script and this should be saved for the website only
chelav <- cheldat %>%
mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
group_by(date) %>%
summarise(meantemp = mean(Temp_C, na.rm = TRUE),
meanDO = mean(DO_mgL, na.rm = TRUE))
chel_temp_plot <- chelav %>%
ggplot(aes(x = date, y = meantemp))+geom_line()+xlab("Date")+ylab("Temperature (Â°C)")+theme_bw()
ggplotly(chel_temp_plot)
copy NUL .nojekyll
